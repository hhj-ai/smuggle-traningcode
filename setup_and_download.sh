#!/bin/bash

# ==========================================
# AURORA Resource Setup (Aliyun/CN Mirror Optimized)
# Downloads: Datasets AND Models (Local Dir)
# ==========================================

# 1. åˆå§‹åŒ–ç›®å½•
echo "ğŸ“‚ åˆå§‹åŒ–ç›®å½•ç»“æ„..."
mkdir -p ./data/yfcc100m
mkdir -p ./data/benchmarks
mkdir -p ./data/test_images
mkdir -p ./output/checkpoints
mkdir -p ./models

# 2. Python ä¸‹è½½è„šæœ¬ (å†…ç½® HF é•œåƒåŠ é€Ÿ)
echo "------------------------------------------------"
echo "ğŸš€ å¯åŠ¨é«˜é€Ÿä¸‹è½½å™¨ (ä½¿ç”¨ hf-mirror.com)..."
echo "------------------------------------------------"

cat <<EOF > _mirror_downloader.py
import os
import json
import shutil
from tqdm import tqdm
from PIL import Image
import io
import sys

# [CRITICAL] å¼ºåˆ¶ä½¿ç”¨å›½å†…é•œåƒ
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
# å¼€å¯ HF ä¸“ç”¨ä¼ è¾“åŠ é€Ÿ (å¦‚æœç¯å¢ƒæ”¯æŒ)
os.environ["HF_HUB_ENABLE_HF_TRANSFER"] = "0" 

print(f"ğŸŒ å·²å¯ç”¨é•œåƒåŠ é€Ÿ: {os.environ['HF_ENDPOINT']}")

from huggingface_hub import hf_hub_download, snapshot_download
from datasets import load_dataset

# ==========================================
# ä»»åŠ¡ A: ä¸‹è½½æ¨¡å‹ (Qwen + DeepSeek)
# ==========================================
def download_models():
    print("\nğŸ¤– [ä»»åŠ¡ A] ä¸‹è½½æ¨¡å‹æƒé‡åˆ° ./models/ ...")
    
    # 1. VLM: Qwen3-VL-8B-Instruct
    print("   â¬‡ï¸  æ­£åœ¨ä¸‹è½½ Qwen/Qwen3-VL-8B-Instruct (å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...")
    try:
        snapshot_download(
            repo_id="Qwen/Qwen3-VL-8B-Instruct",
            local_dir="./models/Qwen3-VL-8B-Instruct",
            local_dir_use_symlinks=False,  # ç¡®ä¿ä¸‹è½½çš„æ˜¯çœŸå®æ–‡ä»¶ï¼Œä¸æ˜¯è½¯é“¾æ¥
            resume_download=True,
            max_workers=8  # é˜¿é‡Œäº‘å¸¦å®½é€šå¸¸è¾ƒå¤§ï¼Œå¼€å¤šçº¿ç¨‹
        )
        print("   âœ… Qwen3-VL ä¸‹è½½å®Œæˆã€‚")
    except Exception as e:
        print(f"   âŒ Qwen ä¸‹è½½å¤±è´¥: {e}")

    # 2. Verifier: DeepSeek-R1-Distill-Qwen-7B
    print("   â¬‡ï¸  æ­£åœ¨ä¸‹è½½ deepseek-ai/DeepSeek-R1-Distill-Qwen-7B...")
    try:
        snapshot_download(
            repo_id="deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
            local_dir="./models/DeepSeek-R1-Distill-Qwen-7B",
            local_dir_use_symlinks=False,
            resume_download=True,
            max_workers=8
        )
        print("   âœ… DeepSeek-R1 ä¸‹è½½å®Œæˆã€‚")
    except Exception as e:
        print(f"   âŒ DeepSeek ä¸‹è½½å¤±è´¥: {e}")

# ==========================================
# ä»»åŠ¡ B: ä¸‹è½½ Benchmark æ•°æ®
# ==========================================
def download_data():
    print("\nğŸ“Š [ä»»åŠ¡ B] ä¸‹è½½æµ‹è¯•æ•°æ®é›†...")

    # Task 1: POPE (ä» hf-mirror æ‹‰å–)
    try:
        print("   â¬‡ï¸  ä¸‹è½½ POPE...")
        file_path = hf_hub_download(
            repo_id="shiyue/POPE", 
            filename="coco_pope_random.json", 
            repo_type="dataset",
            local_dir="./data/benchmarks"
        )
        target = "./data/benchmarks/pope_coco_random.json"
        # ä¿®æ­£è·¯å¾„
        if os.path.abspath(file_path) != os.path.abspath(target):
            shutil.move(file_path, target)
        print("   âœ… POPE å‡†å¤‡å°±ç»ªã€‚")
    except Exception as e:
        print(f"   âŒ POPE å¤±è´¥: {e}")

    # Task 2: MMHal-Bench (ä» hf-mirror åŠ è½½å¹¶å¯¼å‡º)
    try:
        print("   â¬‡ï¸  å¤„ç† MMHal-Bench...")
        dataset = load_dataset("Shengcao1006/MMHal-Bench", split="test")
        export_data = []
        
        # é˜¿é‡Œäº‘æœåŠ¡å™¨é€šå¸¸å¯ä»¥ç›´æ¥å¤„ç†å›¾ç‰‡å¯¹è±¡
        for idx, item in enumerate(tqdm(dataset, desc="   å¯¼å‡º MMHal å›¾ç‰‡")):
            entry = {
                "question_id": idx,
                "question": item.get("question", ""),
                "gt_answer": item.get("answer", ""),
                "image_id": f"mmhal_{idx}.jpg"
            }
            img = item.get("image")
            if img:
                img_path = f"./data/test_images/mmhal_{idx}.jpg"
                if not os.path.exists(img_path):
                    img.convert("RGB").save(img_path)
            export_data.append(entry)
        
        with open("./data/benchmarks/mmhal_bench.json", "w", encoding='utf-8') as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False)
        print("   âœ… MMHal å‡†å¤‡å°±ç»ªã€‚")
    except Exception as e:
        print(f"   âŒ MMHal å¤±è´¥: {e}")

    # Task 3: YFCC100M (ä½¿ç”¨é•œåƒæºæµå¼ä¸‹è½½)
    print("\nğŸ–¼ï¸  [ä»»åŠ¡ C] ä¸‹è½½ YFCC100M è®­ç»ƒå›¾ (ç›®æ ‡: 50,000 å¼ )...")
    ROOT_DIR = "./data/yfcc100m"
    existing = len([f for f in os.listdir(ROOT_DIR) if f.endswith('.jpg')])
    
    if existing >= 50000:
        print(f"   âœ… å·²å­˜åœ¨ {existing} å¼ å›¾ç‰‡ï¼Œè·³è¿‡ä¸‹è½½ã€‚")
        return

    try:
        # dalle-mini å­é›†åœ¨é•œåƒç«™é€šå¸¸æœ‰ç¼“å­˜ï¼Œé€Ÿåº¦å¿«
        ds = load_dataset("dalle-mini/YFCC100M_OpenAI_subset", split="train", streaming=True)
        count = existing
        pbar = tqdm(total=50000, initial=count, unit="img")
        
        for i, item in enumerate(ds):
            if count >= 50000: break
            
            save_path = os.path.join(ROOT_DIR, f"yfcc_{i}.jpg")
            if os.path.exists(save_path): continue
            
            try:
                img_obj = item.get("img") or item.get("image")
                # å¤„ç† bytes ç±»å‹
                if isinstance(img_obj, dict) and 'bytes' in img_obj: 
                     img_obj = img_obj['bytes']
                if isinstance(img_obj, bytes): 
                    img_obj = Image.open(io.BytesIO(img_obj))
                
                if img_obj:
                    img_obj.convert("RGB").save(save_path, "JPEG")
                    count += 1
                    pbar.update(1)
            except Exception: 
                pass # å¿½ç•¥æŸåå›¾ç‰‡
                
        pbar.close()
        print(f"   âœ… YFCC ä¸‹è½½å®Œæˆï¼Œå…± {count} å¼ ã€‚")
    except Exception as e:
        print(f"   âŒ YFCC ä¸‹è½½ä¸­æ–­: {e}")

if __name__ == "__main__":
    download_models()
    download_data()
EOF

# 3. æ‰§è¡Œ Python è„šæœ¬
python _mirror_downloader.py

# 4. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
rm _mirror_downloader.py

echo "------------------------------------------------"
echo "ğŸ‰ ç¯å¢ƒå‡†å¤‡å®Œæˆï¼"
echo "   - æ¨¡å‹è·¯å¾„: ./models/"
echo "   - æ•°æ®è·¯å¾„: ./data/"
echo "ğŸ‘‰ ç°åœ¨è¿è¡Œ: accelerate launch aurora_train.py"
