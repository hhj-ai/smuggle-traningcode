#!/bin/bash

# ==========================================
# AURORA Resource Setup (Fixed Version)
# - Fixes POPE 404 error (Correct subpath)
# - Fixes MMHal trust_remote_code error
# - Keeps Aliyun Mirror acceleration
# ==========================================

# 1. åˆå§‹åŒ–ç›®å½•
echo "ğŸ“‚ åˆå§‹åŒ–ç›®å½•ç»“æ„..."
mkdir -p ./data/yfcc100m
mkdir -p ./data/benchmarks
mkdir -p ./data/test_images
mkdir -p ./output/checkpoints
mkdir -p ./models

# 2. Python ä¸‹è½½è„šæœ¬
echo "------------------------------------------------"
echo "ğŸš€ å¯åŠ¨ä¿®å¤åçš„ä¸‹è½½å™¨..."
echo "------------------------------------------------"

cat <<EOF > _mirror_downloader.py
import os
import json
import shutil
from tqdm import tqdm
from PIL import Image
import io
import sys

# [CRITICAL] å¼ºåˆ¶ä½¿ç”¨å›½å†…é•œåƒ
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
os.environ["HF_HUB_ENABLE_HF_TRANSFER"] = "0" 

print(f"ğŸŒ å·²å¯ç”¨é•œåƒåŠ é€Ÿ: {os.environ['HF_ENDPOINT']}")

from huggingface_hub import hf_hub_download, snapshot_download
from datasets import load_dataset

# ==========================================
# ä»»åŠ¡ A: ä¸‹è½½æ¨¡å‹
# ==========================================
def download_models():
    print("\nğŸ¤– [ä»»åŠ¡ A] æ£€æŸ¥æ¨¡å‹æƒé‡...")
    
    # 1. VLM
    qwen_path = "./models/Qwen3-VL-8B-Instruct"
    if os.path.exists(os.path.join(qwen_path, "config.json")):
        print(f"   âœ… Qwen3-VL å·²å­˜åœ¨ï¼Œè·³è¿‡ã€‚")
    else:
        print("   â¬‡ï¸  æ­£åœ¨ä¸‹è½½ Qwen3-VL (å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...")
        try:
            snapshot_download(
                repo_id="Qwen/Qwen3-VL-8B-Instruct",
                local_dir=qwen_path,
                local_dir_use_symlinks=False,
                resume_download=True,
                max_workers=8
            )
            print("   âœ… Qwen3-VL ä¸‹è½½å®Œæˆã€‚")
        except Exception as e:
            print(f"   âŒ Qwen ä¸‹è½½å¤±è´¥: {e}")

    # 2. Verifier
    ds_path = "./models/DeepSeek-R1-Distill-Qwen-7B"
    if os.path.exists(os.path.join(ds_path, "config.json")):
        print(f"   âœ… DeepSeek-R1 å·²å­˜åœ¨ï¼Œè·³è¿‡ã€‚")
    else:
        print("   â¬‡ï¸  æ­£åœ¨ä¸‹è½½ DeepSeek-R1...")
        try:
            snapshot_download(
                repo_id="deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
                local_dir=ds_path,
                local_dir_use_symlinks=False,
                resume_download=True,
                max_workers=8
            )
            print("   âœ… DeepSeek-R1 ä¸‹è½½å®Œæˆã€‚")
        except Exception as e:
            print(f"   âŒ DeepSeek ä¸‹è½½å¤±è´¥: {e}")

# ==========================================
# ä»»åŠ¡ B: ä¸‹è½½æ•°æ® (ä¿®å¤ç‰ˆ)
# ==========================================
def download_data():
    print("\nğŸ“Š [ä»»åŠ¡ B] ä¸‹è½½æµ‹è¯•æ•°æ®é›†...")

    # Task 1: POPE (ä¿®å¤è·¯å¾„é”™è¯¯)
    pope_target = "./data/benchmarks/pope_coco_random.json"
    if os.path.exists(pope_target):
        print("   âœ… POPE æ•°æ®å·²å­˜åœ¨ï¼Œè·³è¿‡ã€‚")
    else:
        try:
            print("   â¬‡ï¸  ä¸‹è½½ POPE (shiyue/POPE)...")
            # ä¿®æ­£ï¼šæ–‡ä»¶åœ¨ repo çš„ output/coco/ å­ç›®å½•ä¸‹ï¼Œä¸æ˜¯æ ¹ç›®å½•
            file_path = hf_hub_download(
                repo_id="shiyue/POPE", 
                filename="output/coco/coco_pope_random.json", # <--- ä¿®å¤ç‚¹
                repo_type="dataset",
                local_dir="./data/benchmarks"
            )
            # ç§»åŠ¨å¹¶é‡å‘½åä¸ºæ ‡å‡†æ–‡ä»¶å
            if os.path.exists(file_path):
                shutil.move(file_path, pope_target)
                # æ¸…ç† hf ä¸‹è½½ç”Ÿæˆçš„ç©ºç›®å½•ç»“æ„
                shutil.rmtree("./data/benchmarks/output", ignore_errors=True)
            print("   âœ… POPE å‡†å¤‡å°±ç»ªã€‚")
        except Exception as e:
            print(f"   âŒ POPE å¤±è´¥: {e}")
            print("   (å¦‚æœä¾ç„¶å¤±è´¥ï¼Œeval.py ä¼šè·³è¿‡æ­¤é¡¹ï¼Œä¸å½±å“è®­ç»ƒ)")

    # Task 2: MMHal-Bench (ä¿®å¤ trust_remote_code)
    mmhal_target = "./data/benchmarks/mmhal_bench.json"
    if os.path.exists(mmhal_target):
         print("   âœ… MMHal-Bench æ•°æ®å·²å­˜åœ¨ï¼Œè·³è¿‡ã€‚")
    else:
        try:
            print("   â¬‡ï¸  å¤„ç† MMHal-Bench (å« trust_remote_code=True)...")
            # ä¿®æ­£ï¼šæ·»åŠ  trust_remote_code=True
            dataset = load_dataset(
                "Shengcao1006/MMHal-Bench", 
                split="test", 
                trust_remote_code=True  # <--- ä¿®å¤ç‚¹ï¼šå…è®¸æ‰§è¡Œè‡ªå®šä¹‰ä»£ç 
            )
            
            export_data = []
            for idx, item in enumerate(tqdm(dataset, desc="   å¯¼å‡º MMHal å›¾ç‰‡")):
                entry = {
                    "question_id": idx,
                    "question": item.get("question", ""),
                    "gt_answer": item.get("answer", ""),
                    "image_id": f"mmhal_{idx}.jpg"
                }
                img = item.get("image")
                if img:
                    img_path = f"./data/test_images/mmhal_{idx}.jpg"
                    if not os.path.exists(img_path):
                        img.convert("RGB").save(img_path)
                export_data.append(entry)
            
            with open(mmhal_target, "w", encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False)
            print("   âœ… MMHal å‡†å¤‡å°±ç»ªã€‚")
        except Exception as e:
            print(f"   âŒ MMHal å¤±è´¥: {e}")

    # Task 3: YFCC100M
    print("\nğŸ–¼ï¸  [ä»»åŠ¡ C] æ£€æŸ¥ YFCC100M...")
    ROOT_DIR = "./data/yfcc100m"
    existing = len([f for f in os.listdir(ROOT_DIR) if f.endswith('.jpg')])
    
    if existing >= 50000:
        print(f"   âœ… å·²å­˜åœ¨ {existing} å¼ å›¾ç‰‡ï¼Œè·³è¿‡ã€‚")
        return

    try:
        ds = load_dataset("dalle-mini/YFCC100M_OpenAI_subset", split="train", streaming=True)
        count = existing
        pbar = tqdm(total=50000, initial=count, unit="img")
        
        for i, item in enumerate(ds):
            if count >= 50000: break
            save_path = os.path.join(ROOT_DIR, f"yfcc_{i}.jpg")
            if os.path.exists(save_path): continue
            
            try:
                img_obj = item.get("img") or item.get("image")
                if isinstance(img_obj, dict) and 'bytes' in img_obj: img_obj = img_obj['bytes']
                if isinstance(img_obj, bytes): img_obj = Image.open(io.BytesIO(img_obj))
                if img_obj:
                    img_obj.convert("RGB").save(save_path, "JPEG")
                    count += 1
                    pbar.update(1)
            except: pass
                
        pbar.close()
        print(f"   âœ… YFCC ä¸‹è½½å®Œæˆã€‚")
    except Exception as e:
        print(f"   âŒ YFCC ä¸‹è½½ä¸­æ–­: {e}")

if __name__ == "__main__":
    download_models()
    download_data()
EOF

# 3. æ‰§è¡Œ
python _mirror_downloader.py
rm _mirror_downloader.py

echo "------------------------------------------------"
echo "ğŸ‰ ä¿®å¤å®Œæˆï¼è¯·ç»§ç»­ã€‚"
