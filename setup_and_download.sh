#!/bin/bash

# ==========================================
# AURORA Project Data Setup Script (Enterprise Compatible)
# Environment: Linux (Old wget compatible + HF Mirror)
# ==========================================

set -e  # é‡åˆ°é”™è¯¯ç«‹å³åœæ­¢

echo "ğŸš€ Starting AURORA Environment Setup & Data Download..."

# 1. åˆ›å»ºç›®å½•ç»“æ„
echo "ğŸ“‚ Creating directory structure..."
mkdir -p ./data/yfcc100m
mkdir -p ./data/benchmarks
mkdir -p ./data/test_images
mkdir -p ./output/checkpoints

echo "âœ… Directories ready: ./data, ./output"

# 2. ä¸‹è½½ Benchmark æ•°æ® (å…¼å®¹æ—§ç‰ˆ wget å’Œ curl)
echo "ğŸ“Š Downloading Benchmark Datasets..."

POPE_URL="https://raw.githubusercontent.com/lavis-nlp/POPE/main/output/coco/coco_pope_random.json"
# ä½¿ç”¨ HF é•œåƒåŠ é€Ÿ MMHal ä¸‹è½½
MMHAL_URL="https://hf-mirror.com/datasets/SJTU-LIT/MMHal-Bench/resolve/main/mmhal_bench.json"

download_file() {
    url=$1
    dest=$2
    name=$3
    
    if [ ! -f "$dest" ]; then
        echo "   - Downloading $name..."
        # å°è¯• wget (å…¼å®¹æ—§ç‰ˆï¼Œæ— è¿›åº¦æ¡)
        if command -v wget >/dev/null 2>&1; then
            wget -q -O "$dest" "$url"
        # å›é€€åˆ° curl
        elif command -v curl >/dev/null 2>&1; then
            curl -L -o "$dest" "$url" -s
        else
            echo "âš ï¸  Error: Neither wget nor curl found. Please download $url manually."
            return 1
        fi
        
        if [ $? -eq 0 ]; then
            echo "     âœ… $name downloaded."
        else
            echo "     âŒ Failed to download $name. Check network/proxy."
        fi
    else
        echo "   - $name already exists."
    fi
}

download_file "$POPE_URL" "./data/benchmarks/pope_coco_random.json" "POPE"
download_file "$MMHAL_URL" "./data/benchmarks/mmhal_bench.json" "MMHal-Bench"

# 3. ä¸‹è½½ YFCC100M å›¾ç‰‡ (Python è„šæœ¬ + é•œåƒåŠ é€Ÿ)
echo "ğŸ–¼ï¸  Downloading YFCC100M Images (Target: 50,000)..."

cat <<EOF > _downloader.py
import os
import asyncio
import aiohttp
from io import BytesIO
from PIL import Image
from tqdm import tqdm

# === å…³é”®ï¼šæ³¨å…¥å›½å†…é•œåƒç¯å¢ƒå˜é‡ ===
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
print(f"ğŸŒ Enable HF Mirror: {os.environ['HF_ENDPOINT']}")

from datasets import load_dataset

# Configuration aligned with aurora_train.py
ROOT_DIR = "./data/yfcc100m"
TARGET_COUNT = 50000 
CONCURRENCY = 100 # é€‚å½“é™ä½å¹¶å‘ä»¥é¿å…å†…ç½‘é˜²ç«å¢™é™æµ

async def download_image(session, url, idx):
    try:
        timeout = aiohttp.ClientTimeout(total=15)
        async with session.get(url, timeout=timeout) as response:
            if response.status == 200:
                content = await response.read()
                try:
                    Image.open(BytesIO(content)).verify()
                except:
                    return False
                path = os.path.join(ROOT_DIR, f"yfcc_{idx}.jpg")
                with open(path, "wb") as f:
                    f.write(content)
                return True
    except:
        return False
    return False

async def main():
    # Check existing
    existing = [f for f in os.listdir(ROOT_DIR) if f.endswith('.jpg')]
    if len(existing) >= TARGET_COUNT:
        print(f"âœ… Found {len(existing)} images. Skipping download.")
        return

    print(f"ğŸŒŠ Streaming metadata from Hugging Face Mirror...")
    
    # å°è¯•åŠ è½½æ•°æ®é›†ï¼Œå¢åŠ å®¹é”™
    try:
        # é¦–é€‰æº
        ds = load_dataset("limingcv/YFCC100M_OpenAI_subset", split="train", streaming=True, trust_remote_code=True)
    except Exception as e:
        print(f"âš ï¸  Primary source failed: {e}")
        try:
            # å¤‡ç”¨æº (é€šå¸¸æ›´ç¨³å®š)
            ds = load_dataset("dbrtag/yfcc100m", split="train", streaming=True, trust_remote_code=True)
        except Exception as e2:
            print(f"âŒ  All sources failed. ä½ çš„ç½‘ç»œå¯èƒ½æ— æ³•è®¿é—®å¤–éƒ¨ HF é•œåƒã€‚")
            print(f"Error details: {e2}")
            return

    print(f"â¬‡ï¸  Downloading missing images (Target: {TARGET_COUNT})...")
    
    async with aiohttp.ClientSession() as session:
        tasks = []
        downloaded = len(existing)
        pbar = tqdm(total=TARGET_COUNT, initial=downloaded, unit="img")
        
        for i, item in enumerate(ds):
            if downloaded >= TARGET_COUNT:
                break
            
            if os.path.exists(os.path.join(ROOT_DIR, f"yfcc_{i}.jpg")):
                continue

            # å…¼å®¹ä¸åŒæ•°æ®é›†çš„ URL å­—æ®µå
            url = item.get('url') or item.get('URL') or item.get('img_url') or item.get('download_url')
            if not url: continue
            
            tasks.append(asyncio.create_task(download_image(session, url, i)))
            
            if len(tasks) >= CONCURRENCY:
                results = await asyncio.gather(*tasks)
                success = sum(results)
                downloaded += success
                pbar.update(success)
                tasks = []
        
        if tasks:
            results = await asyncio.gather(*tasks)
            downloaded += sum(results)
            pbar.update(sum(results))
        
        pbar.close()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except Exception as e:
        print(f"\nâŒ Python script execution failed: {e}")
        print("å»ºè®®æ‰‹åŠ¨æ£€æŸ¥: ping hf-mirror.com æ˜¯å¦é€šç•…")

EOF

# Run the embedded python downloader
python _downloader.py

# Cleanup
rm _downloader.py

echo "ğŸ‰ All data downloaded successfully!"
echo "   - Images: ./data/yfcc100m"
echo "   - Benchmarks: ./data/benchmarks"
echo "   - Checkpoints: ./output/checkpoints"
echo ""
echo "ğŸ‘‰ You can now run training directly: accelerate launch aurora_train.py"
