#!/bin/bash
# --- ç»Ÿä¸€è·¯å¾„å®šä¹‰ ---
CODE_DIR=$(cd "$(dirname "$0")"; pwd)
RES_DIR=$(realpath "$CODE_DIR/../aurora_resources")
MODELS_DIR="$RES_DIR/models"
DATA_DIR="$RES_DIR/data"
OUTPUT_DIR="$RES_DIR/output"

# ç”Ÿäº§çŽ¯å¢ƒåŽŸå§‹çŽ¯å¢ƒè·¯å¾„
PROD_ENV="/mnt/dolphinfs/ssd_pool/docker/user/hadoop-nlp-sh02/native_mm/zhangmanyuan/zhangquan/agent/xl/hhj-train/smuggle-traningcode/aurora_env"

echo "ðŸ“‚ [GPU] æ£€æŸ¥èµ„æºç›®å½•: $RES_DIR"

# 1. èµ„äº§å­˜åœ¨æ€§è‡ªæ£€
MISSING=0
for m in "Qwen3-VL-8B-Instruct" "DeepSeek-R1-Distill-Qwen-7B" "grounding-dino-base" "clip-vit-base-patch32" "minilm"; do
    if [ ! -d "$MODELS_DIR/$m" ]; then
        echo "âŒ ç¼ºå¤±æ¨¡åž‹ç›®å½•: $MODELS_DIR/$m"
        MISSING=1
    elif [ ! -f "$MODELS_DIR/$m/config.json" ]; then
        echo "âŒ æ¨¡åž‹ç›®å½•ä¸ºç©ºæˆ–ä¸å®Œæ•´ (ç¼ºå°‘ config.json): $MODELS_DIR/$m"
        MISSING=1
    fi
done

if [ $MISSING -eq 1 ]; then
    echo "ðŸš¨ èµ„äº§ç¼ºå¤±ï¼è¯·å…ˆåœ¨ CPU æœåŠ¡å™¨è¿è¡Œ cpu.sh æˆ–æ£€æŸ¥æŒ‚è½½ã€‚"
    exit 1
fi

# 2. è¿›ç¨‹æ¸…ç†
pkill -9 -f aurora_train.py 2>/dev/null
pkill -9 -f accelerate 2>/dev/null
sleep 2

# 3. çŽ¯å¢ƒå˜é‡
export TRANSFORMERS_OFFLINE=1
export HF_DATASETS_OFFLINE=1
export HF_HOME="$RES_DIR/hf_cache"
export OMP_NUM_THREADS=1

# ============================================================
# 4. è‡ªåŠ¨æ£€æµ‹ GPU æ˜¾å­˜ï¼Œæ™ºèƒ½åˆ†é…è®­ç»ƒå¡ä¸Žå·¥å…·å¡
# ============================================================
TRAIN_THRESHOLD_MIB=80000   # è®­ç»ƒå¡è‡³å°‘éœ€è¦ 80 GiB ç©ºé—²
TOOL_THRESHOLD_MIB=4000     # å·¥å…·å¡è‡³å°‘éœ€è¦ 4 GiB ç©ºé—² (DINO+CLIP ~1.5GB)

echo "ðŸ” è‡ªåŠ¨æ£€æµ‹ GPU æ˜¾å­˜å ç”¨..."
TRAIN_GPUS=()
TOOL_GPU_CANDIDATES=()

for gpu_id in 0 1 2 3 4 5 6 7; do
    free_mib=$(nvidia-smi --query-gpu=memory.free --format=csv,noheader,nounits -i "$gpu_id" 2>/dev/null | tr -d ' ')
    if [ -z "$free_mib" ]; then continue; fi

    total_mib=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits -i "$gpu_id" 2>/dev/null | tr -d ' ')
    used_pct=$(( (total_mib - free_mib) * 100 / total_mib ))
    echo "  GPU $gpu_id: ${free_mib} MiB ç©ºé—² / ${total_mib} MiB æ€»é‡ (å·²ç”¨ ${used_pct}%)"

    if [ "$free_mib" -ge "$TRAIN_THRESHOLD_MIB" ]; then
        TRAIN_GPUS+=("$gpu_id")
    elif [ "$free_mib" -ge "$TOOL_THRESHOLD_MIB" ]; then
        TOOL_GPU_CANDIDATES+=("$gpu_id")
    else
        echo "    âš ï¸  GPU $gpu_id ç©ºé—²ä¸è¶³ï¼Œè·³è¿‡"
    fi
done

NUM_TRAIN=${#TRAIN_GPUS[@]}
if [ "$NUM_TRAIN" -eq 0 ]; then
    echo "ðŸš¨ æ²¡æœ‰ GPU ç©ºé—²æ˜¾å­˜ >= ${TRAIN_THRESHOLD_MIB} MiBï¼Œæ— æ³•å¯åŠ¨è®­ç»ƒï¼"
    echo "   è¯·æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–ä»»åŠ¡å ç”¨ GPUï¼Œæˆ–é™ä½Ž TRAIN_THRESHOLD_MIBã€‚"
    exit 1
fi

echo ""
echo "âœ… å¯ç”¨è®­ç»ƒ GPU: [${TRAIN_GPUS[*]}] (å…± ${NUM_TRAIN} å¼ )"

# å†³å®šå·¥å…·è®¾å¤‡ï¼šä¼˜å…ˆç”¨æ˜¾å­˜ä¸å¤Ÿè®­ç»ƒä½†å¤Ÿè·‘å·¥å…·çš„å¡
TOOL_DEVICE_ARG=""
if [ ${#TOOL_GPU_CANDIDATES[@]} -gt 0 ]; then
    TOOL_PHYS_GPU=${TOOL_GPU_CANDIDATES[0]}
    # CUDA_VISIBLE_DEVICES: è®­ç»ƒå¡åœ¨å‰ï¼Œå·¥å…·å¡åœ¨æœ«å°¾
    ALL_GPUS=("${TRAIN_GPUS[@]}" "$TOOL_PHYS_GPU")
    CUDA_VIS=$(IFS=,; echo "${ALL_GPUS[*]}")
    # å·¥å…·å¡çš„é€»è¾‘ç´¢å¼• = è®­ç»ƒå¡æ•°é‡ (0-indexed)
    TOOL_DEVICE_ARG="--tool_device cuda:${NUM_TRAIN}"
    echo "ðŸ”§ å·¥å…·ä¸“ç”¨ GPU: ç‰©ç† GPU $TOOL_PHYS_GPU â†’ é€»è¾‘ cuda:${NUM_TRAIN}"
else
    # æ²¡æœ‰ä¸“ç”¨å·¥å…·å¡ï¼Œå·¥å…·åœ¨ rank 0 çš„è®­ç»ƒå¡ä¸ŠåŠ è½½
    CUDA_VIS=$(IFS=,; echo "${TRAIN_GPUS[*]}")
    echo "ðŸ”§ æ— ä¸“ç”¨å·¥å…·å¡ï¼Œå·¥å…·å°†åŠ è½½åœ¨ rank 0 çš„è®­ç»ƒ GPU ä¸Š"
fi

export CUDA_VISIBLE_DEVICES=$CUDA_VIS
echo "ðŸ“‹ CUDA_VISIBLE_DEVICES=$CUDA_VIS"
echo "ðŸ“‹ è®­ç»ƒè¿›ç¨‹æ•°: $NUM_TRAIN"
echo ""

# ============================================================
# 5. æ¿€æ´»çŽ¯å¢ƒä¸Žä¸¥æ ¼è‡ªæ£€
# ============================================================
ACTIVATED=0
if [ -f "$PROD_ENV/bin/activate" ]; then
    echo "ðŸ å°è¯•æ¿€æ´»ç”Ÿäº§çŽ¯å¢ƒ: $PROD_ENV"
    source "$PROD_ENV/bin/activate"
    ACTIVATED=1
elif [ -f "$RES_DIR/env/bin/activate" ]; then
    echo "ðŸ å°è¯•æ¿€æ´»æœ¬åœ°çŽ¯å¢ƒ: $RES_DIR/env"
    source "$RES_DIR/env/bin/activate"
    ACTIVATED=1
fi

if [ $ACTIVATED -eq 0 ]; then
    echo "ðŸš¨ è‡´å‘½é”™è¯¯ï¼šæ‰¾ä¸åˆ°å¯ç”¨çš„è™šæ‹ŸçŽ¯å¢ƒï¼è¯·æ£€æŸ¥ PROD_ENV æˆ–è¿è¡Œ cpu.sh åˆ›å»ºçŽ¯å¢ƒã€‚"
    exit 1
fi

# éªŒè¯çŽ¯å¢ƒæœ‰æ•ˆæ€§
python -c "import torch; import transformers; print(f'âœ… çŽ¯å¢ƒéªŒè¯é€šè¿‡: Torch {torch.__version__}')" 2>/dev/null
if [ $? -ne 0 ]; then
    echo "ðŸš¨ çŽ¯å¢ƒæ¿€æ´»å¤±è´¥ï¼šå½“å‰ Python æ— æ³•åŠ è½½ torch/transformersã€‚"
    echo "   å½“å‰ Python: $(which python)"
    exit 1
fi

# 6. æ–­ç‚¹ç»­ä¼ æ£€æµ‹
RESUME_ARG=""
LATEST_CKPT="$OUTPUT_DIR/checkpoints/latest"
if [ -L "$LATEST_CKPT" ] || [ -d "$LATEST_CKPT" ]; then
    if [ -f "$(realpath "$LATEST_CKPT")/training_state.pt" ]; then
        echo "ðŸ”„ æ£€æµ‹åˆ°å·²æœ‰ checkpoint: $(realpath "$LATEST_CKPT")"
        echo "   å°†è‡ªåŠ¨ä»Žä¸Šæ¬¡ä¸­æ–­å¤„ç»§ç»­è®­ç»ƒ"
        RESUME_ARG="--resume_from latest"
    fi
fi

# 7. å¯åŠ¨
echo "ðŸ”¥ å¯åŠ¨ AURORA è®­ç»ƒ..."
LOG_NAME="train_final_$(date +%Y%m%d_%H%M).log"

setsid accelerate launch \
    --multi_gpu --num_processes "$NUM_TRAIN" --mixed_precision bf16 \
    aurora_train.py \
    --model_dir "$MODELS_DIR" \
    --data_dir "$DATA_DIR/yfcc100m" \
    --minilm_path "$MODELS_DIR/minilm" \
    --output_dir "$OUTPUT_DIR" \
    $TOOL_DEVICE_ARG $RESUME_ARG > "$LOG_NAME" 2>&1 < /dev/null &

echo "ðŸš€ å·²åŽå°å¯åŠ¨ã€‚æ—¥å¿—: tail -n +1 -f $LOG_NAME"
