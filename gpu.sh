#!/bin/bash
# --- 1. ç»å¯¹è·¯å¾„å®šä¹‰ ---
CODE_ROOT=$(cd "$(dirname "$0")"; pwd)
RES_ROOT=$(realpath "$CODE_ROOT/../aurora_resources")
PROD_ENV="/mnt/dolphinfs/ssd_pool/docker/user/hadoop-nlp-sh02/native_mm/zhangmanyuan/zhangquan/agent/xl/hhj-train/smuggle-traningcode/aurora_env"

# æ ¸å¿ƒèµ„æºè·¯å¾„
MODELS_DIR="$RES_ROOT/models"
DATA_DIR="$RES_ROOT/data"
OUTPUT_DIR="$RES_ROOT/output"

# --- 2. çŽ¯å¢ƒå˜é‡æžè‡´è°ƒä¼˜ ---
export TRANSFORMERS_OFFLINE=1
export HF_DATASETS_OFFLINE=1
export HF_HOME="$RES_ROOT/hf_cache"
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7

# æ ¸å¿ƒï¼šé™åˆ¶å¤šè¿›ç¨‹ CPU æŠ¢å ï¼Œé˜²æ­¢ RAM å´©æºƒ
export OMP_NUM_THREADS=1
export MKL_NUM_THREADS=1

# ç¨³å®šæ€§å¢žå¼ºï¼šé’ˆå¯¹æ—§å†…æ ¸ (4.18) çš„ NCCL ä¼˜åŒ–
export NCCL_P2P_DISABLE=1
export NCCL_IB_DISABLE=0
export NCCL_SOCKET_IFNAME=eth0,enp,bond # æ ¹æ®ä½ çš„ç½‘å¡åè‡ªåŠ¨åŒ¹é…
export NCCL_TIMEOUT=14400  # 4 å°æ—¶
export TORCH_DISTRIBUTED_DEBUG=DETAIL

# æ¿€æ´»çŽ¯å¢ƒ
source "$PROD_ENV/bin/activate"

# --- 3. å¯åŠ¨ ---
echo "ðŸ”¥ [GPU] å¯åŠ¨æžè‡´ç¨³å®šç‰ˆè®­ç»ƒ (Timeout: 2h, Sequential: ON)..."
LOG_NAME="train_stable_$(date +%Y%m%d_%H%M).log"

setsid accelerate launch \
    --multi_gpu \
    --num_processes 8 \
    --mixed_precision bf16 \
    aurora_train.py \
    --mode AURORA \
    --model_dir "$MODELS_DIR" \
    --data_dir "$DATA_DIR" \
    --minilm_path "$MODELS_DIR/minilm" \
    --output_dir "$OUTPUT_DIR" \
    --batch_size 8 \
    --attack_weight 5.0 > "$LOG_NAME" 2>&1 < /dev/null &

echo "ðŸš€ å·²å¯åŠ¨ç¨³å®šæ€§æ¨¡å¼ï¼æ—¥å¿—: tail -f $LOG_NAME"
