#!/bin/bash
# =========================================================
# 2_fixed_install.sh (GPU æœåŠ¡å™¨ - ä¿®å¤é¡ºåºç‰ˆ)
# ç‰¹æ€§: 
# 1. ä¸¥æ ¼æŒ‰é¡ºåºå®‰è£… Packaging -> Numpy -> Torch -> FlashAttn
# 2. ä¸ä¼šè¦†ç›–/ä¿®æ”¹å½“å‰ç›®å½•ä¸‹çš„ models.py
# =========================================================

BASE_DIR="./offline_packages"
PYTHON_TGZ="$BASE_DIR/python_runtime/python-3.10.tar.gz"
WHEEL_DIR="$BASE_DIR/wheels"
INSTALL_ROOT="./aurora_env_root"
VENV_DIR="aurora_env"

echo "ğŸš€ [GPU Server] å¼€å§‹ä¸¥æ ¼é¡ºåºå®‰è£…..."

# 1. å‡†å¤‡ç¯å¢ƒ (è‹¥å·²å­˜åœ¨åˆ™è·³è¿‡è§£å‹ï¼ŒèŠ‚çœæ—¶é—´)
if [ ! -d "$INSTALL_ROOT" ]; then
    echo "ğŸ è§£å‹ Python 3.10..."
    mkdir -p $INSTALL_ROOT
    tar -xzf $PYTHON_TGZ -C $INSTALL_ROOT
fi

# ç¡®å®š Python è·¯å¾„
if [ -d "$INSTALL_ROOT/python" ]; then 
    LOCAL_PYTHON="$INSTALL_ROOT/python/bin/python3"
else 
    LOCAL_PYTHON="$INSTALL_ROOT/bin/python3"
fi

# é‡å»ºè™šæ‹Ÿç¯å¢ƒ
echo "ğŸ“¦ é‡å»ºè™šæ‹Ÿç¯å¢ƒ..."
rm -rf $VENV_DIR
$LOCAL_PYTHON -m venv $VENV_DIR
source $VENV_DIR/bin/activate

# é…ç½® pip å¼ºåˆ¶ç¦»çº¿
pip config set global.no-index true > /dev/null 2>&1
pip config set global.find-links $(pwd)/$WHEEL_DIR > /dev/null 2>&1

install_pkg() {
    # å¼ºåˆ¶åªä»æœ¬åœ°æ‰¾
    pip install "$@" --no-index --find-links=$WHEEL_DIR
}

# =========================================================
# 2. å…³é”®ä¿®å¤æ­¥éª¤ï¼šæŒ‰é¡ºåºå®‰è£…
# =========================================================

echo "ğŸ§± [1/5] å®‰è£…æ„å»ºå·¥å…· (Packaging, Ninja, Numpy)..."
# å¿…é¡»æœ€å…ˆå®‰è£…ï¼Œå¦åˆ™ FlashAttn ç¼–è¯‘ä¼šæŠ¥é”™ "No module named packaging"
install_pkg wheel setuptools
install_pkg packaging ninja psutil
install_pkg "numpy<2.0.0"

# éªŒè¯å…³é”®åŒ…
python -c "import packaging; import numpy; print(f'   âœ… Environment Ready: Numpy {numpy.__version__}')" || exit 1

echo "ğŸ® [2/5] å®‰è£… NVIDIA ä¾èµ–åº“..."
# PyTorch 2.x å¼ºä¾èµ–è¿™äº›åº“ï¼Œå¿…é¡»æ‰‹åŠ¨å®‰è£…
install_pkg nvidia-cuda-runtime-cu12 nvidia-cublas-cu12 nvidia-cudnn-cu12
install_pkg nvidia-cuda-nvrtc-cu12 nvidia-cuda-cupti-cu12 nvidia-cufft-cu12 
install_pkg nvidia-curand-cu12 nvidia-cusolver-cu12 nvidia-cusparse-cu12 
install_pkg nvidia-nccl-cu12 nvidia-nvtx-cu12 triton

echo "ğŸ”¥ [3/5] å®‰è£… PyTorch..."
install_pkg torch torchvision torchaudio
# éªŒè¯ Torch
python -c "import torch; print(f'   âœ… Torch {torch.__version__} (CUDA Available: {torch.cuda.is_available()})')" || exit 1

echo "âš¡ [4/5] ç¼–è¯‘ Flash Attention..."
# æ­¤æ—¶ç¯å¢ƒé‡Œå·²ç»æœ‰äº† torch, packaging, ninjaï¼Œç¼–è¯‘åº”è¯¥èƒ½é€šè¿‡
install_pkg flash-attn --no-build-isolation

echo "ğŸ¤— [5/5] å®‰è£… Transformers & å…¶ä»–..."
if [ -f "$WHEEL_DIR/transformers-main.zip" ]; then
    echo "   -> ä»æºç  Zip å®‰è£… Transformers..."
    unzip -q -o "$WHEEL_DIR/transformers-main.zip" -d ./temp_tf
    pip install ./temp_tf/transformers-main --no-index --find-links=$WHEEL_DIR
    rm -rf ./temp_tf
else
    install_pkg transformers
fi

# å®‰è£…å‰©ä½™ä¾èµ–
install_pkg accelerate huggingface_hub datasets sentence-transformers Pillow easyocr
install_pkg scipy termcolor timm rich questionary aiohttp protobuf sentencepiece pandas

echo "------------------------------------------------"
echo "ğŸ‰ å®‰è£…å®Œæˆï¼"
echo "ğŸ‘‰ å¯åŠ¨å‘½ä»¤: source $VENV_DIR/bin/activate"
