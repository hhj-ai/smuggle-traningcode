#!/bin/bash
# --- 1. ç»å¯¹è·¯å¾„å®šä¹‰ ---
CODE_ROOT=$(cd "$(dirname "$0")"; pwd)
RES_ROOT=$(realpath "$CODE_ROOT/../aurora_resources")
PROD_ENV="/mnt/dolphinfs/ssd_pool/docker/user/hadoop-nlp-sh02/native_mm/zhangmanyuan/zhangquan/agent/xl/hhj-train/smuggle-traningcode/aurora_env"

# æ ¸å¿ƒèµ„æºè·¯å¾„
MODELS_DIR="$RES_ROOT/models"
DATA_DIR="$RES_ROOT/data"
OUTPUT_DIR="$RES_ROOT/output"

# --- 2. çŽ¯å¢ƒå˜é‡æžè‡´è°ƒä¼˜ ---
export TRANSFORMERS_OFFLINE=1
export HF_DATASETS_OFFLINE=1
export HF_HOME="$RES_ROOT/hf_cache"
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7

# æ ¸å¿ƒï¼šé™åˆ¶å¤šè¿›ç¨‹ CPU æŠ¢å ï¼Œé˜²æ­¢ RAM å´©æºƒ
export OMP_NUM_THREADS=1
export MKL_NUM_THREADS=1
# å¢žåŠ  NCCL ç¨³å®šæ€§é…ç½®
export NCCL_TIMEOUT=7200
export NCCL_IB_DISABLE=0 # å¦‚æžœé›†ç¾¤æ”¯æŒ RDMAï¼Œè¯·ä¿æŒ 0

# æ¿€æ´»çŽ¯å¢ƒ
source "$PROD_ENV/bin/activate"

# --- 3. å¯åŠ¨ ---
echo "ðŸ”¥ [GPU] å¯åŠ¨æžè‡´ç¨³å®šç‰ˆè®­ç»ƒ (Timeout: 2h, Sequential: ON)..."
LOG_NAME="train_stable_$(date +%Y%m%d_%H%M).log"

setsid accelerate launch \
    --multi_gpu \
    --num_processes 8 \
    --mixed_precision bf16 \
    aurora_train.py \
    --mode AURORA \
    --model_dir "$MODELS_DIR" \
    --data_dir "$DATA_DIR" \
    --minilm_path "$MODELS_DIR/minilm" \
    --output_dir "$OUTPUT_DIR" \
    --batch_size 32 \
    --attack_weight 5.0 > "$LOG_NAME" 2>&1 < /dev/null &

echo "ðŸš€ å·²å¯åŠ¨ç¨³å®šæ€§æ¨¡å¼ï¼æ—¥å¿—: tail -f $LOG_NAME"
